{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting Text using PyPDF2"
      ],
      "metadata": {
        "id": "gRdGeXrpM-Rc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AegAD12ej-q",
        "outputId": "06c29165-ff5a-43ed-fd10-a420f0b7e44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/232.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def extract_text_with_pyPDF(PDF_File):\n",
        "\n",
        "    pdf_reader = PdfReader(PDF_File)\n",
        "\n",
        "    raw_text = ''\n",
        "\n",
        "    for i, page in enumerate(pdf_reader.pages):\n",
        "\n",
        "        text = page.extract_text()\n",
        "        if text:\n",
        "            raw_text += text\n",
        "\n",
        "    return raw_text"
      ],
      "metadata": {
        "id": "drvkd63De2k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_with_pyPDF = extract_text_with_pyPDF(\"text.pdf\")\n",
        "print(text_with_pyPDF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzsjF-4Ie9RG",
        "outputId": "8d7315b6-2cdb-4490-bc02-214447f2e6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "PILLI SAI NISHANTH \n",
            "Final Year Student, VIT Vellore \n",
            " \n",
            "Email ID:  nishanth.pilli@gmail.com \n",
            "Mobile: 9347575252 \n",
            "GitHub: https://github.com/dr4g0n7ly \n",
            " \n",
            "An ever-passionate Computer Scientist with experience developing frontend, backend, blockchain \n",
            "as well as full stack AI applications in addition to experience in UI design. I enjoy keeping myself \n",
            "up to date with current research and love trying to try my hands out at new developments. \n",
            " \n",
            "Educational Qualification: \n",
            " B.Tech Computer Science and Engineering since 2020 at Vellore Institute of Technology, \n",
            "Vellore with GPA 8.15 \n",
            " Senior Secondary Education (MPC) from 2018-2020 at Chirec International school, \n",
            "Hyderabad with 93.5% \n",
            " Secondary Education from 2016-2018 at Chirec International school, Hyderabad with 92% \n",
            " \n",
            "Technical Skills: \n",
            " Programming languages: Python, Java, Solidity \n",
            " Frameworks: Pytorch, FastAI, React JS, Hardhat \n",
            " Databases: MongoDB \n",
            " AI Development \n",
            " Web Development \n",
            " \n",
            "Project Undertaken: \n",
            "LLM Context Injection using Knowledge Graphs \n",
            " Developed a personalized educational site allowing users to context inject various types of \n",
            "text resources such as PDFs, CSV, MD files using FastAPI, and utilizing semantic search and \n",
            "knowledge graphs with Llama2 for personalized quizzes, summaries and chatbots \n",
            "Federated Learning Model \n",
            " Built a federated learning model pipeline using Flower that can train the model using \n",
            "multiple client trainers while keeping data private \n",
            " Trained and tested a simple MNIST dataset with an accuracy of 97% using Pytorch \n",
            "Parkinson’s Detection Model \n",
            " Built and deployed a Parkinson’s detection model with an accuracy of 94%  \n",
            " Utilized FastAI to perform transfer learning on ResNet34 and EfficientNetB2  \n",
            " Compared results with a PyTorch CNN model, random forests, and SVM models  \n",
            " \n",
            "Rabit Coin \n",
            " Developed a fully functioning and transparent banking system using Solidity to build the \n",
            "smart contract backend and ReactJS framework to build the front-end \n",
            " Implemented collateral document submission using NFT.Storage to store Metadata \n",
            " Allow users a much cheaper and democratic alternative to loans at the cost of privacy \n",
            " \n",
            "TrackPay \n",
            " Developed a full-stack MERN application that allows users to track their financial spendings \n",
            " Utilized the MongoDB database through the Mongoose framework to store and manage \n",
            "encrypted financial data. \n",
            "Internships:  \n",
            " The Global Academic Internship Programme (GAIP) with the NUS School of Computing, \n",
            "Singapore and Amazon SageMaker Data Analytics (June-July 2023) \n",
            "o Worked with NUS faculties to develop and increase understand of various machine \n",
            "learning and deep learning models \n",
            "o Led a team of 5 to build a Bi-LSTM model that detects violence through videos in 3 \n",
            "weeks \n",
            "o Achieved one of the highest rankings in a cohort comprising of 60 academic interns \n",
            "Experience \n",
            "Student Technical Community - Senior Core Developer and Designer \n",
            " Worked as a designer and developer for multiple STC projects, including the Recruitment \n",
            "Website, Flow-In, Chrome Pets, and Social Media initiatives.  \n",
            " Mentored junior members of the team, providing guidance and support in web \n",
            "development and UI design to foster growth and improve skillsets. \n",
            "Key Skills: \n",
            " IBM Certified – Artificial Intelligence Analyst \n",
            " Experience in developing PyTorch AI, Ethereum Blockchain and MERN stack applications \n",
            " Basic understanding of concepts of high-level deep-learning concepts such as transformers, \n",
            "GANs, federated learning, vector embeddings and transfer learning \n",
            " Ability to work by myself without the need of constant guidance \n",
            " Resolute analytical and problem-solving prowess, coupled with a talent for seamless \n",
            "collaboration \n",
            " Excellent verbal and written communication skills \n",
            " Ability to assist in Quality documentation  \n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = len(text_with_pyPDF)\n",
        "print(length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azah40u88qI9",
        "outputId": "fe893f38-94e1-465e-d7d3-2f1d1216ada1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_tokens = text_with_pyPDF.split()"
      ],
      "metadata": {
        "id": "HmMz4RSXfRYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.output { width: 100% !important; }</style>\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CPGtGNhipzV_",
        "outputId": "3a1245fc-89f0-4d48-d401-4e61afa2bb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.output { width: 100% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "\n",
        "step_size = length//30 - 40\n",
        "window_size = length//30\n",
        "\n",
        "\n",
        "for i in range(0, len(text_tokens), step_size):\n",
        "    window = text_tokens[i: i+window_size]\n",
        "    if len(window) < window_size:\n",
        "        break\n",
        "    sentences.append(window)\n",
        "\n",
        "paragraphs = []\n",
        "\n",
        "for s in sentences:\n",
        "  paragraph = \" \".join(s)\n",
        "  paragraphs.append(paragraph)\n",
        "\n",
        "for p in paragraphs:\n",
        "  print(p)\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47cWiAaNgD1A",
        "outputId": "5b8ee91e-32cc-41ae-bb47-6f011a5b2e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PILLI SAI NISHANTH Final Year Student, VIT Vellore Email ID: nishanth.pilli@gmail.com Mobile: 9347575252 GitHub: https://github.com/dr4g0n7ly An ever-passionate Computer Scientist with experience developing frontend, backend, blockchain as well as full stack AI applications in addition to experience in UI design. I enjoy keeping myself up to date with current research and love trying to try my hands out at new developments. Educational Qualification:  B.Tech Computer Science and Engineering since 2020 at Vellore Institute of Technology, Vellore with GPA 8.15  Senior Secondary Education (MPC) from 2018-2020 at Chirec International school, Hyderabad with 93.5%  Secondary Education from 2016-2018 at Chirec International school, Hyderabad with 92% Technical Skills:  Programming languages: Python, Java, Solidity  Frameworks: Pytorch, FastAI, React JS, Hardhat  Databases: MongoDB  AI Development\n",
            "\n",
            "\n",
            "\n",
            "at Chirec International school, Hyderabad with 93.5%  Secondary Education from 2016-2018 at Chirec International school, Hyderabad with 92% Technical Skills:  Programming languages: Python, Java, Solidity  Frameworks: Pytorch, FastAI, React JS, Hardhat  Databases: MongoDB  AI Development  Web Development Project Undertaken: LLM Context Injection using Knowledge Graphs  Developed a personalized educational site allowing users to context inject various types of text resources such as PDFs, CSV, MD files using FastAPI, and utilizing semantic search and knowledge graphs with Llama2 for personalized quizzes, summaries and chatbots Federated Learning Model  Built a federated learning model pipeline using Flower that can train the model using multiple client trainers while keeping data private  Trained and tested a simple MNIST dataset with an accuracy\n",
            "\n",
            "\n",
            "\n",
            "quizzes, summaries and chatbots Federated Learning Model  Built a federated learning model pipeline using Flower that can train the model using multiple client trainers while keeping data private  Trained and tested a simple MNIST dataset with an accuracy of 97% using Pytorch Parkinson’s Detection Model  Built and deployed a Parkinson’s detection model with an accuracy of 94%  Utilized FastAI to perform transfer learning on ResNet34 and EfficientNetB2  Compared results with a PyTorch CNN model, random forests, and SVM models Rabit Coin  Developed a fully functioning and transparent banking system using Solidity to build the smart contract backend and ReactJS framework to build the front-end  Implemented collateral document submission using NFT.Storage to store Metadata  Allow users a much cheaper\n",
            "\n",
            "\n",
            "\n",
            " Developed a fully functioning and transparent banking system using Solidity to build the smart contract backend and ReactJS framework to build the front-end  Implemented collateral document submission using NFT.Storage to store Metadata  Allow users a much cheaper and democratic alternative to loans at the cost of privacy TrackPay  Developed a full-stack MERN application that allows users to track their financial spendings  Utilized the MongoDB database through the Mongoose framework to store and manage encrypted financial data. Internships:  The Global Academic Internship Programme (GAIP) with the NUS School of Computing, Singapore and Amazon SageMaker Data Analytics (June-July 2023) o Worked with NUS faculties to develop and increase understand of various machine learning and deep learning models o Led a team of\n",
            "\n",
            "\n",
            "\n",
            "Internship Programme (GAIP) with the NUS School of Computing, Singapore and Amazon SageMaker Data Analytics (June-July 2023) o Worked with NUS faculties to develop and increase understand of various machine learning and deep learning models o Led a team of 5 to build a Bi-LSTM model that detects violence through videos in 3 weeks o Achieved one of the highest rankings in a cohort comprising of 60 academic interns Experience Student Technical Community - Senior Core Developer and Designer  Worked as a designer and developer for multiple STC projects, including the Recruitment Website, Flow-In, Chrome Pets, and Social Media initiatives.  Mentored junior members of the team, providing guidance and support in web development and UI design to foster growth and improve skillsets. Key Skills:\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for s in sentences:\n",
        "  print(s)\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScRX2o0tNUA8",
        "outputId": "7d652b21-b43b-438d-953a-40403fe43c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PILLI', 'SAI', 'NISHANTH', 'Final', 'Year', 'Student,', 'VIT', 'Vellore', 'Email', 'ID:', 'nishanth.pilli@gmail.com', 'Mobile:', '9347575252', 'GitHub:', 'https://github.com/dr4g0n7ly', 'An', 'ever-passionate', 'Computer', 'Scientist', 'with', 'experience', 'developing', 'frontend,', 'backend,', 'blockchain', 'as', 'well', 'as', 'full', 'stack', 'AI', 'applications', 'in', 'addition', 'to', 'experience', 'in', 'UI', 'design.', 'I', 'enjoy', 'keeping', 'myself', 'up', 'to', 'date', 'with', 'current', 'research', 'and', 'love', 'trying', 'to', 'try', 'my', 'hands', 'out', 'at', 'new', 'developments.', 'Educational', 'Qualification:', '\\uf0b7', 'B.Tech', 'Computer', 'Science', 'and', 'Engineering', 'since', '2020', 'at', 'Vellore', 'Institute', 'of', 'Technology,', 'Vellore', 'with', 'GPA', '8.15', '\\uf0b7', 'Senior', 'Secondary', 'Education', '(MPC)', 'from', '2018-2020', 'at', 'Chirec', 'International', 'school,', 'Hyderabad', 'with', '93.5%', '\\uf0b7', 'Secondary', 'Education', 'from', '2016-2018', 'at', 'Chirec', 'International', 'school,', 'Hyderabad', 'with', '92%', 'Technical', 'Skills:', '\\uf0b7', 'Programming', 'languages:', 'Python,', 'Java,', 'Solidity', '\\uf0b7', 'Frameworks:', 'Pytorch,', 'FastAI,', 'React', 'JS,', 'Hardhat', '\\uf0b7', 'Databases:', 'MongoDB', '\\uf0b7', 'AI', 'Development']\n",
            "\n",
            "\n",
            "\n",
            "['at', 'Chirec', 'International', 'school,', 'Hyderabad', 'with', '93.5%', '\\uf0b7', 'Secondary', 'Education', 'from', '2016-2018', 'at', 'Chirec', 'International', 'school,', 'Hyderabad', 'with', '92%', 'Technical', 'Skills:', '\\uf0b7', 'Programming', 'languages:', 'Python,', 'Java,', 'Solidity', '\\uf0b7', 'Frameworks:', 'Pytorch,', 'FastAI,', 'React', 'JS,', 'Hardhat', '\\uf0b7', 'Databases:', 'MongoDB', '\\uf0b7', 'AI', 'Development', '\\uf0b7', 'Web', 'Development', 'Project', 'Undertaken:', 'LLM', 'Context', 'Injection', 'using', 'Knowledge', 'Graphs', '\\uf0b7', 'Developed', 'a', 'personalized', 'educational', 'site', 'allowing', 'users', 'to', 'context', 'inject', 'various', 'types', 'of', 'text', 'resources', 'such', 'as', 'PDFs,', 'CSV,', 'MD', 'files', 'using', 'FastAPI,', 'and', 'utilizing', 'semantic', 'search', 'and', 'knowledge', 'graphs', 'with', 'Llama2', 'for', 'personalized', 'quizzes,', 'summaries', 'and', 'chatbots', 'Federated', 'Learning', 'Model', '\\uf0b7', 'Built', 'a', 'federated', 'learning', 'model', 'pipeline', 'using', 'Flower', 'that', 'can', 'train', 'the', 'model', 'using', 'multiple', 'client', 'trainers', 'while', 'keeping', 'data', 'private', '\\uf0b7', 'Trained', 'and', 'tested', 'a', 'simple', 'MNIST', 'dataset', 'with', 'an', 'accuracy']\n",
            "\n",
            "\n",
            "\n",
            "['quizzes,', 'summaries', 'and', 'chatbots', 'Federated', 'Learning', 'Model', '\\uf0b7', 'Built', 'a', 'federated', 'learning', 'model', 'pipeline', 'using', 'Flower', 'that', 'can', 'train', 'the', 'model', 'using', 'multiple', 'client', 'trainers', 'while', 'keeping', 'data', 'private', '\\uf0b7', 'Trained', 'and', 'tested', 'a', 'simple', 'MNIST', 'dataset', 'with', 'an', 'accuracy', 'of', '97%', 'using', 'Pytorch', 'Parkinson’s', 'Detection', 'Model', '\\uf0b7', 'Built', 'and', 'deployed', 'a', 'Parkinson’s', 'detection', 'model', 'with', 'an', 'accuracy', 'of', '94%', '\\uf0b7', 'Utilized', 'FastAI', 'to', 'perform', 'transfer', 'learning', 'on', 'ResNet34', 'and', 'EfficientNetB2', '\\uf0b7', 'Compared', 'results', 'with', 'a', 'PyTorch', 'CNN', 'model,', 'random', 'forests,', 'and', 'SVM', 'models', 'Rabit', 'Coin', '\\uf0b7', 'Developed', 'a', 'fully', 'functioning', 'and', 'transparent', 'banking', 'system', 'using', 'Solidity', 'to', 'build', 'the', 'smart', 'contract', 'backend', 'and', 'ReactJS', 'framework', 'to', 'build', 'the', 'front-end', '\\uf0b7', 'Implemented', 'collateral', 'document', 'submission', 'using', 'NFT.Storage', 'to', 'store', 'Metadata', '\\uf0b7', 'Allow', 'users', 'a', 'much', 'cheaper']\n",
            "\n",
            "\n",
            "\n",
            "['\\uf0b7', 'Developed', 'a', 'fully', 'functioning', 'and', 'transparent', 'banking', 'system', 'using', 'Solidity', 'to', 'build', 'the', 'smart', 'contract', 'backend', 'and', 'ReactJS', 'framework', 'to', 'build', 'the', 'front-end', '\\uf0b7', 'Implemented', 'collateral', 'document', 'submission', 'using', 'NFT.Storage', 'to', 'store', 'Metadata', '\\uf0b7', 'Allow', 'users', 'a', 'much', 'cheaper', 'and', 'democratic', 'alternative', 'to', 'loans', 'at', 'the', 'cost', 'of', 'privacy', 'TrackPay', '\\uf0b7', 'Developed', 'a', 'full-stack', 'MERN', 'application', 'that', 'allows', 'users', 'to', 'track', 'their', 'financial', 'spendings', '\\uf0b7', 'Utilized', 'the', 'MongoDB', 'database', 'through', 'the', 'Mongoose', 'framework', 'to', 'store', 'and', 'manage', 'encrypted', 'financial', 'data.', 'Internships:', '\\uf0b7', 'The', 'Global', 'Academic', 'Internship', 'Programme', '(GAIP)', 'with', 'the', 'NUS', 'School', 'of', 'Computing,', 'Singapore', 'and', 'Amazon', 'SageMaker', 'Data', 'Analytics', '(June-July', '2023)', 'o', 'Worked', 'with', 'NUS', 'faculties', 'to', 'develop', 'and', 'increase', 'understand', 'of', 'various', 'machine', 'learning', 'and', 'deep', 'learning', 'models', 'o', 'Led', 'a', 'team', 'of']\n",
            "\n",
            "\n",
            "\n",
            "['Internship', 'Programme', '(GAIP)', 'with', 'the', 'NUS', 'School', 'of', 'Computing,', 'Singapore', 'and', 'Amazon', 'SageMaker', 'Data', 'Analytics', '(June-July', '2023)', 'o', 'Worked', 'with', 'NUS', 'faculties', 'to', 'develop', 'and', 'increase', 'understand', 'of', 'various', 'machine', 'learning', 'and', 'deep', 'learning', 'models', 'o', 'Led', 'a', 'team', 'of', '5', 'to', 'build', 'a', 'Bi-LSTM', 'model', 'that', 'detects', 'violence', 'through', 'videos', 'in', '3', 'weeks', 'o', 'Achieved', 'one', 'of', 'the', 'highest', 'rankings', 'in', 'a', 'cohort', 'comprising', 'of', '60', 'academic', 'interns', 'Experience', 'Student', 'Technical', 'Community', '-', 'Senior', 'Core', 'Developer', 'and', 'Designer', '\\uf0b7', 'Worked', 'as', 'a', 'designer', 'and', 'developer', 'for', 'multiple', 'STC', 'projects,', 'including', 'the', 'Recruitment', 'Website,', 'Flow-In,', 'Chrome', 'Pets,', 'and', 'Social', 'Media', 'initiatives.', '\\uf0b7', 'Mentored', 'junior', 'members', 'of', 'the', 'team,', 'providing', 'guidance', 'and', 'support', 'in', 'web', 'development', 'and', 'UI', 'design', 'to', 'foster', 'growth', 'and', 'improve', 'skillsets.', 'Key', 'Skills:']\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sentences))"
      ],
      "metadata": {
        "id": "9eviBhsfgkDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a831ef-294c-4b12-c011-bb890b617198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appending text (test)"
      ],
      "metadata": {
        "id": "4MRepeG5M5Ct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('extracted_text.txt', 'a')\n",
        "for p in paragraphs:\n",
        "  file.write(p)\n",
        "  file.write('\\n')\n",
        "  file.write('\\n')\n",
        "file.close()"
      ],
      "metadata": {
        "id": "fUu4zVobow7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KDYfquCCMBVS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}